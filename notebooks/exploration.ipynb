{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load TMDB datasets\n",
    "tmdb_movies = pd.read_csv(\"../data/tmdb_5000_movies.csv\")\n",
    "tmdb_credits = pd.read_csv(\"../data/tmdb_5000_credits.csv\")\n",
    "\n",
    "# Load MovieLens ratings\n",
    "ratings = pd.read_csv(\"../data/ratings.csv\")\n",
    "\n",
    "print(\"TMDB Movies:\", tmdb_movies.shape)\n",
    "print(\"TMDB Credits:\", tmdb_credits.shape)\n",
    "print(\"Ratings:\", ratings.shape)\n",
    "\n",
    "# Merge TMDB movies and credits on movie ID\n",
    "movies = tmdb_movies.merge(tmdb_credits, left_on=\"id\", right_on=\"movie_id\")\n",
    "\n",
    "# print(movies.shape)\n",
    "movies.head(2)\n",
    "\n",
    "# Select relevant columns\n",
    "movies = movies[['id','original_title','overview','genres','keywords','cast','crew']]\n",
    "movies.head(2)\n",
    "\n",
    "# Convert JSON-like text to lists\n",
    "import ast\n",
    "\n",
    "def extract_names(obj):\n",
    "    try:\n",
    "        items = ast.literal_eval(obj)\n",
    "        return [i['name'].lower().replace(\" \", \"\") for i in items]\n",
    "    except:\n",
    "        return []\n",
    "movies['genres'] = movies['genres'].apply(extract_names)\n",
    "movies['keywords'] = movies['keywords'].apply(extract_names)\n",
    "\n",
    "movies[['original_title','genres','keywords']].head(2)\n",
    "\n",
    "#   Extract top 3 cast members\n",
    "def get_top3_cast(obj):\n",
    "    try:\n",
    "        items = ast.literal_eval(obj)\n",
    "        names = [i['name'].lower().replace(\" \", \"\") for i in items[:3]]\n",
    "        return names\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "movies['cast'] = movies['cast'].apply(get_top3_cast)\n",
    "movies[['original_title','cast']].head(2)\n",
    "\n",
    "#   Extract director from crew\n",
    "def get_director(obj):\n",
    "    try:\n",
    "        items = ast.literal_eval(obj)\n",
    "        for i in items:\n",
    "            if i['job'] == 'Director':\n",
    "                return [i['name'].lower().replace(\" \", \"\")]\n",
    "        return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "movies['director'] = movies['crew'].apply(get_director)\n",
    "movies[['original_title','director']].head(2)\n",
    "\n",
    "#   Process overview text\n",
    "movies['overview'] = movies['overview'].fillna(\"\").apply(lambda x: x.lower().split())\n",
    "movies[['original_title','overview']].head(2)\n",
    "\n",
    "#   Create movie profile by combining all features\n",
    "movies['movie_profile'] = (\n",
    "    movies['overview'] +\n",
    "    movies['genres'] +\n",
    "    movies['keywords'] +\n",
    "    movies['cast'] +\n",
    "    movies['director']\n",
    ")\n",
    "movies['movie_profile'] = movies['movie_profile'].apply(lambda x: \" \".join(x))\n",
    "movies[['original_title','movie_profile']].head(2)\n",
    "\n",
    "#   Final selection of columns\n",
    "final_movies = movies[['id','original_title','movie_profile']]\n",
    "final_movies.head()\n",
    "\n",
    "# Vectorize movie profiles\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vectors = cv.fit_transform(final_movies['movie_profile']).toarray()\n",
    "\n",
    "print(vectors.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(vectors)\n",
    "print(similarity.shape)\n",
    "\n",
    "#   Create a mapping from movie titles to indices\n",
    "movie_index = pd.Series(final_movies.index, \n",
    "                        index=final_movies['original_title']).drop_duplicates()\n",
    "movie_index[\"Inception\"]\n",
    "\n",
    "#   Recommendation function\n",
    "def recommend(movie):\n",
    "    # Get index of the movie\n",
    "    idx = movie_index.get(movie)\n",
    "\n",
    "    if idx is None:\n",
    "        print(\"Movie not found in dataset\")\n",
    "        return\n",
    "\n",
    "    # Get similarity scores for this movie\n",
    "    sim_scores = list(enumerate(similarity[idx]))\n",
    "\n",
    "    # Sort movies based on similarity (excluding itself)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
    "\n",
    "    # Get movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return top 10 similar movies\n",
    "    return final_movies['original_title'].iloc[movie_indices]\n",
    "\n",
    "recommend(\"Inception\")\n",
    "print(recommend(\"The Dark Knight\"))\n",
    "print()\n",
    "print(recommend(\"The Godfather\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ba3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"../data/ratings.csv\")\n",
    "ratings.head()\n",
    "\n",
    "print(\"Total ratings:\", len(ratings))\n",
    "print(\"Unique users:\", ratings['userId'].nunique())\n",
    "print(\"Unique movies:\", ratings['movieId'].nunique())\n",
    "print(\"Average ratings per user:\", len(ratings) / ratings['userId'].nunique())\n",
    "print(\"Average ratings per movie:\", len(ratings) / ratings['movieId'].nunique())\n",
    "\n",
    "\n",
    "user_movie_matrix = ratings.pivot_table(\n",
    "    index='userId',\n",
    "    columns='movieId',\n",
    "    values='rating'\n",
    ")\n",
    "\n",
    "print(user_movie_matrix.shape)\n",
    "user_movie_matrix.head()\n",
    "\n",
    "missing = user_movie_matrix.isna().sum().sum()\n",
    "total = user_movie_matrix.size\n",
    "print(f\"Sparsity: {round((missing/total) * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8240b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv(\"../data/links.csv\")\n",
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tamil_2011_2019 = pd.read_csv(\"../data/tamil_movies_2011-2019.csv\")\n",
    "tamil_2015_2025 = pd.read_csv(\"../data/tamil_movies_2015-2025.csv\")\n",
    "tamil_imdb_2023 = pd.read_csv(\"../data/imdb_tamil_2023.csv\")\n",
    "\n",
    "print(\"2011-2019 shape:\", tamil_2011_2019.shape)\n",
    "print(\"2015-2025 shape:\", tamil_2015_2025.shape)\n",
    "print(\"2023 IMDb shape:\", tamil_imdb_2023.shape)\n",
    "\n",
    "print(\"Columns 2011-2019:\\n\", tamil_2011_2019.columns)\n",
    "print(\"\\nColumns 2015-2025:\\n\", tamil_2015_2025.columns)\n",
    "print(\"\\nColumns IMDb 2023:\\n\", tamil_imdb_2023.columns)\n",
    "\n",
    "t1 = tamil_2011_2019.copy()\n",
    "\n",
    "# Rename to our common schema\n",
    "t1 = t1.rename(columns={\n",
    "    'MovieName': 'title',\n",
    "    'Genre': 'genres',\n",
    "    'Director': 'director',\n",
    "    'Actor': 'cast',\n",
    "    'Rating': 'imdb_rating'      # use this as IMDb rating\n",
    "})\n",
    "\n",
    "# Create empty overview (this dataset doesn't have one)\n",
    "t1['overview'] = \"\"\n",
    "\n",
    "# Create unique dummy IDs (so they don’t clash with TMDB)\n",
    "t1['id'] = range(100000, 100000 + len(t1))\n",
    "\n",
    "# Keep only the columns we need\n",
    "t1 = t1[['id','title','overview','genres','cast','director','imdb_rating']]\n",
    "\n",
    "t1.head(2)\n",
    "\n",
    "\n",
    "t3 = tamil_2015_2025.copy()\n",
    "\n",
    "t3 = t3.rename(columns={\n",
    "    'tittle': 'title',     # note: your file spells it \"tittle\"\n",
    "    'genre': 'genres',\n",
    "    'director': 'director',\n",
    "    'cast': 'cast'\n",
    "})\n",
    "\n",
    "# But add imdb_rating as NaN (not available here)\n",
    "t3['imdb_rating'] = None\n",
    "\n",
    "# Create unique dummy IDs\n",
    "t3['id'] = range(200000, 200000 + len(t3))\n",
    "\n",
    "t3 = t3[['id','title','overview','genres','cast','director','imdb_rating']]\n",
    "\n",
    "t3.head(2)\n",
    "\n",
    "\n",
    "t4 = tamil_imdb_2023.copy()\n",
    "\n",
    "t4 = t4.rename(columns={\n",
    "    'Movie Name': 'title',\n",
    "    'IMdb rating': 'imdb_rating',\n",
    "    'Description': 'overview'\n",
    "})\n",
    "\n",
    "# We don’t have genres, cast, director here → create empty placeholders\n",
    "t4['genres'] = \"\"\n",
    "t4['cast'] = \"\"\n",
    "t4['director'] = \"\"\n",
    "\n",
    "# Create unique dummy IDs\n",
    "t4['id'] = range(300000, 300000 + len(t4))\n",
    "\n",
    "t4 = t4[['id','title','overview','genres','cast','director','imdb_rating']]\n",
    "\n",
    "t4.head(2)\n",
    "\n",
    "tamil_movies = pd.concat([t1, t3, t4], ignore_index=True)\n",
    "\n",
    "print(\"Combined Tamil shape:\", tamil_movies.shape)\n",
    "tamil_movies.head(3)\n",
    "\n",
    "\n",
    "def to_list(x):\n",
    "    if isinstance(x, str):\n",
    "        return [i.strip().lower().replace(\" \", \"\") for i in x.split(',')]\n",
    "    elif isinstance(x, list):\n",
    "        return [i.lower().replace(\" \", \"\") for i in x]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "tamil_movies['genres'] = tamil_movies['genres'].apply(to_list)\n",
    "tamil_movies['cast'] = tamil_movies['cast'].apply(to_list)\n",
    "tamil_movies['director'] = tamil_movies['director'].apply(lambda x: to_list(x))\n",
    "tamil_movies['overview'] = tamil_movies['overview'].fillna(\"\").apply(lambda x: x.lower().split())\n",
    "\n",
    "tamil_movies['movie_profile'] = (\n",
    "    tamil_movies['overview'] +\n",
    "    tamil_movies['genres'] +\n",
    "    tamil_movies['cast'] +\n",
    "    tamil_movies['director']\n",
    ")\n",
    "\n",
    "tamil_movies['movie_profile'] = tamil_movies['movie_profile'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "tamil_movies[['title','movie_profile']].head(2)\n",
    "\n",
    "tamil_final = tamil_movies[['id','title','movie_profile']]\n",
    "tamil_final.head()\n",
    "\n",
    "# Rename original_title → title in Hollywood data\n",
    "final_movies = final_movies.rename(columns={'original_title': 'title'})\n",
    "\n",
    "final_movies_extended = pd.concat([final_movies, tamil_final], ignore_index=True)\n",
    "\n",
    "print(\"Old size:\", final_movies.shape)\n",
    "print(\"New size:\", final_movies_extended.shape)\n",
    "\n",
    "final_movies_extended.to_csv(\"../data/final_movies_extended.csv\", index=False)\n",
    "\n",
    "final_movies_extended.head()\n",
    "final_movies_extended.tail()\n",
    "\n",
    "# If movie_profile is empty, use title words instead\n",
    "final_movies_extended['movie_profile'] = final_movies_extended.apply(\n",
    "    lambda row: row['title'].lower().replace(\".\", \"\").split()\n",
    "    if (isinstance(row['movie_profile'], str) and row['movie_profile'].strip() == \"\")\n",
    "    else row['movie_profile'],\n",
    "    axis=1\n",
    ")\n",
    "final_movies_extended['title'] = final_movies_extended['title'].str.replace(r'^\\d+\\.\\s*', '', regex=True)\n",
    "\n",
    "final_movies_extended.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_movies_extended = pd.read_csv(\"../data/final_movies_extended.csv\")\n",
    "\n",
    "print(final_movies_extended.shape)\n",
    "print(final_movies_extended.columns)\n",
    "\n",
    "# 1) Remove leading numbers like \"206. \"\n",
    "final_movies_extended['title'] = final_movies_extended['title'].str.replace(\n",
    "    r'^\\d+\\.\\s*', '', regex=True\n",
    ")\n",
    "\n",
    "# 2) Fix spacing issues (e.g., \"DoubleX\" -> \"Double X\")\n",
    "final_movies_extended['title'] = final_movies_extended['title'].str.replace(\n",
    "    r'DoubleX', 'Double X', regex=False\n",
    ")\n",
    "\n",
    "# 3) Remove extra spaces and standardize case\n",
    "final_movies_extended['title'] = (\n",
    "    final_movies_extended['title']\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Keep only the first occurrence of each title\n",
    "final_movies_extended = final_movies_extended.drop_duplicates(\n",
    "    subset=['title'], keep='first'\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"New shape after removing duplicates:\", final_movies_extended.shape)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "vectors = cv.fit_transform(final_movies_extended['movie_profile']).toarray()\n",
    "print(\"New vector shape:\", vectors.shape)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(vectors)\n",
    "print(\"Similarity matrix shape:\", similarity.shape)\n",
    "\n",
    "movie_index = pd.Series(\n",
    "    final_movies_extended.index,\n",
    "    index=final_movies_extended['title']\n",
    ").drop_duplicates()\n",
    "\n",
    "def recommend(movie):\n",
    "    idx = movie_index.get(movie)\n",
    "\n",
    "    if idx is None:\n",
    "        print(\"Movie not found in dataset\")\n",
    "        return []\n",
    "\n",
    "    sim_scores = list(enumerate(similarity[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    return final_movies_extended['title'].iloc[movie_indices].tolist()\n",
    "\n",
    "\n",
    "print(\"Recommendations for Inception:\\n\")\n",
    "print(recommend(\"Inception\"))\n",
    "\n",
    "print(\"\\nRecommendations for Jigarthanda Double X:\\n\")\n",
    "print(recommend(\"Jigarthanda Double X\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9257a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"../data/ratings.csv\")\n",
    "movies_ml = pd.read_csv(\"../data/movies.csv\")  \n",
    "links = pd.read_csv(\"../data/links.csv\")\n",
    "\n",
    "print(ratings.head())\n",
    "print(movies_ml.head())\n",
    "print(links.head())\n",
    "\n",
    "\n",
    "user_movie_matrix = ratings.pivot_table(\n",
    "    index='userId',\n",
    "    columns='movieId',\n",
    "    values='rating'\n",
    ")\n",
    "print(user_movie_matrix.shape)\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "movie_similarity_cf = cosine_similarity(\n",
    "    user_movie_matrix.T.fillna(0)\n",
    ")\n",
    "\n",
    "print(movie_similarity_cf.shape)\n",
    "\n",
    "print(movies_ml.columns)\n",
    "\n",
    "movie_id_map = movies_ml.set_index('movieId')['title']\n",
    "\n",
    "def recommend_cf(movie_title):\n",
    "    # find movieId\n",
    "    matches = movies_ml[movies_ml['title'].str.contains(movie_title, case=False)]\n",
    "    if matches.empty:\n",
    "        return []\n",
    "    \n",
    "    movie_id = matches.iloc[0]['movieId']\n",
    "    idx = list(user_movie_matrix.columns).index(movie_id)\n",
    "    \n",
    "    sim_scores = list(enumerate(movie_similarity_cf[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
    "    \n",
    "    movie_indices = [user_movie_matrix.columns[i[0]] for i in sim_scores]\n",
    "    return movie_id_map.loc[movie_indices].tolist()\n",
    "\n",
    "print(recommend_cf(\"Inception\"))\n",
    "print(recommend_cf(\"Toy Story\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a62132",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv(\"../data/links.csv\")\n",
    "\n",
    "# Keep only valid mappings\n",
    "links = links.dropna(subset=['tmdbId'])\n",
    "\n",
    "links['tmdbId'] = links['tmdbId'].astype(int)\n",
    "\n",
    "ml_to_tmdb = links.set_index('movieId')['tmdbId'].to_dict()\n",
    "\n",
    "tmdb_to_content_index = pd.Series(\n",
    "    final_movies_extended.index,\n",
    "    index=final_movies_extended['id']\n",
    ").to_dict()\n",
    "\n",
    "def get_cf_scores(movie_title):\n",
    "    # CF recommendations (MovieLens titles)\n",
    "    cf_movies = recommend_cf(movie_title)\n",
    "    \n",
    "    scores = {}\n",
    "    \n",
    "    for title in cf_movies:\n",
    "        # find MovieLens id\n",
    "        match = movies_ml[movies_ml['title'] == title]\n",
    "        if match.empty:\n",
    "            continue\n",
    "        \n",
    "        ml_id = match.iloc[0]['movieId']\n",
    "        \n",
    "        # map to TMDB\n",
    "        if ml_id not in ml_to_tmdb:\n",
    "            continue\n",
    "        \n",
    "        tmdb_id = ml_to_tmdb[ml_id]\n",
    "        \n",
    "        # map to content index\n",
    "        if tmdb_id not in tmdb_to_content_index:\n",
    "            continue\n",
    "        \n",
    "        content_idx = tmdb_to_content_index[tmdb_id]\n",
    "        scores[content_idx] = 1  # simple uniform score\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def recommend_hybrid(movie, alpha=0.6):\n",
    "    # Content index\n",
    "    idx = movie_index.get(movie)\n",
    "    \n",
    "    if idx is None:\n",
    "        print(\"Movie not found in content dataset\")\n",
    "        return []\n",
    "    \n",
    "    # Content similarity scores\n",
    "    content_scores = list(enumerate(similarity[idx]))\n",
    "    \n",
    "    # Collaborative scores\n",
    "    cf_scores = get_cf_scores(movie)\n",
    "    \n",
    "    hybrid_scores = []\n",
    "    \n",
    "    for i, c_score in content_scores:\n",
    "        cf_score = cf_scores.get(i, 0)\n",
    "        \n",
    "        # Hybrid formula\n",
    "        final_score = alpha * c_score + (1 - alpha) * cf_score\n",
    "        hybrid_scores.append((i, final_score))\n",
    "    \n",
    "    hybrid_scores = sorted(hybrid_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
    "    movie_indices = [i[0] for i in hybrid_scores]\n",
    "    \n",
    "    return final_movies_extended['title'].iloc[movie_indices].tolist()\n",
    "\n",
    "\n",
    "print(\"HYBRID Inception:\\n\")\n",
    "print(recommend_hybrid(\"Inception\"))\n",
    "\n",
    "print(\"\\nHYBRID Toy Story:\\n\")\n",
    "print(recommend_hybrid(\"Toy Story\"))\n",
    "\n",
    "print(\"\\nHYBRID Jigarthanda Double X:\\n\")\n",
    "print(recommend_hybrid(\"Jigarthanda Double X\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
