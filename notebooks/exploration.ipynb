{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbd640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMDB Movies: (4803, 20)\n",
      "TMDB Credits: (4803, 4)\n",
      "Ratings: (100836, 4)\n",
      "(4803, 5000)\n",
      "(4803, 4803)\n",
      "3                         The Dark Knight Rises\n",
      "119                               Batman Begins\n",
      "428                              Batman Returns\n",
      "299                              Batman Forever\n",
      "210                              Batman & Robin\n",
      "1359                                     Batman\n",
      "4638                   Amidst the Devil's Wings\n",
      "9            Batman v Superman: Dawn of Justice\n",
      "3854    Batman: The Dark Knight Returns, Part 2\n",
      "4135                                 Jerusalema\n",
      "Name: original_title, dtype: object\n",
      "\n",
      "2731      The Godfather: Part II\n",
      "1873                  Blood Ties\n",
      "3727                 Snabba Cash\n",
      "867      The Godfather: Part III\n",
      "4065                  Mi America\n",
      "4638    Amidst the Devil's Wings\n",
      "3507                    Deadfall\n",
      "4226                Nueve Reinas\n",
      "444            Road to Perdition\n",
      "1635     The Replacement Killers\n",
      "Name: original_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load TMDB datasets\n",
    "tmdb_movies = pd.read_csv(\"../data/tmdb_5000_movies.csv\")\n",
    "tmdb_credits = pd.read_csv(\"../data/tmdb_5000_credits.csv\")\n",
    "\n",
    "# Load MovieLens ratings\n",
    "ratings = pd.read_csv(\"../data/ratings.csv\")\n",
    "\n",
    "print(\"TMDB Movies:\", tmdb_movies.shape)\n",
    "print(\"TMDB Credits:\", tmdb_credits.shape)\n",
    "print(\"Ratings:\", ratings.shape)\n",
    "\n",
    "# Merge TMDB movies and credits on movie ID\n",
    "movies = tmdb_movies.merge(tmdb_credits, left_on=\"id\", right_on=\"movie_id\")\n",
    "\n",
    "# print(movies.shape)\n",
    "movies.head(2)\n",
    "\n",
    "# Select relevant columns\n",
    "movies = movies[['id','original_title','overview','genres','keywords','cast','crew']]\n",
    "movies.head(2)\n",
    "\n",
    "# Convert JSON-like text to lists\n",
    "import ast\n",
    "\n",
    "def extract_names(obj):\n",
    "    try:\n",
    "        items = ast.literal_eval(obj)\n",
    "        return [i['name'].lower().replace(\" \", \"\") for i in items]\n",
    "    except:\n",
    "        return []\n",
    "movies['genres'] = movies['genres'].apply(extract_names)\n",
    "movies['keywords'] = movies['keywords'].apply(extract_names)\n",
    "\n",
    "movies[['original_title','genres','keywords']].head(2)\n",
    "\n",
    "#   Extract top 3 cast members\n",
    "def get_top3_cast(obj):\n",
    "    try:\n",
    "        items = ast.literal_eval(obj)\n",
    "        names = [i['name'].lower().replace(\" \", \"\") for i in items[:3]]\n",
    "        return names\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "movies['cast'] = movies['cast'].apply(get_top3_cast)\n",
    "movies[['original_title','cast']].head(2)\n",
    "\n",
    "#   Extract director from crew\n",
    "def get_director(obj):\n",
    "    try:\n",
    "        items = ast.literal_eval(obj)\n",
    "        for i in items:\n",
    "            if i['job'] == 'Director':\n",
    "                return [i['name'].lower().replace(\" \", \"\")]\n",
    "        return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "movies['director'] = movies['crew'].apply(get_director)\n",
    "movies[['original_title','director']].head(2)\n",
    "\n",
    "#   Process overview text\n",
    "movies['overview'] = movies['overview'].fillna(\"\").apply(lambda x: x.lower().split())\n",
    "movies[['original_title','overview']].head(2)\n",
    "\n",
    "#   Create movie profile by combining all features\n",
    "movies['movie_profile'] = (\n",
    "    movies['overview'] +\n",
    "    movies['genres'] +\n",
    "    movies['keywords'] +\n",
    "    movies['cast'] +\n",
    "    movies['director']\n",
    ")\n",
    "movies['movie_profile'] = movies['movie_profile'].apply(lambda x: \" \".join(x))\n",
    "movies[['original_title','movie_profile']].head(2)\n",
    "\n",
    "#   Final selection of columns\n",
    "final_movies = movies[['id','original_title','movie_profile']]\n",
    "final_movies.head()\n",
    "\n",
    "# Vectorize movie profiles\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vectors = cv.fit_transform(final_movies['movie_profile']).toarray()\n",
    "\n",
    "print(vectors.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(vectors)\n",
    "print(similarity.shape)\n",
    "\n",
    "#   Create a mapping from movie titles to indices\n",
    "movie_index = pd.Series(final_movies.index, \n",
    "                        index=final_movies['original_title']).drop_duplicates()\n",
    "movie_index[\"Inception\"]\n",
    "\n",
    "#   Recommendation function\n",
    "def recommend(movie):\n",
    "    # Get index of the movie\n",
    "    idx = movie_index.get(movie)\n",
    "\n",
    "    if idx is None:\n",
    "        print(\"Movie not found in dataset\")\n",
    "        return\n",
    "\n",
    "    # Get similarity scores for this movie\n",
    "    sim_scores = list(enumerate(similarity[idx]))\n",
    "\n",
    "    # Sort movies based on similarity (excluding itself)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
    "\n",
    "    # Get movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return top 10 similar movies\n",
    "    return final_movies['original_title'].iloc[movie_indices]\n",
    "\n",
    "recommend(\"Inception\")\n",
    "print(recommend(\"The Dark Knight\"))\n",
    "print()\n",
    "print(recommend(\"The Godfather\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6ba3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ratings: 100836\n",
      "Unique users: 610\n",
      "Unique movies: 9724\n",
      "Average ratings per user: 165.30491803278687\n",
      "Average ratings per movie: 10.369806663924312\n",
      "(610, 9724)\n",
      "Sparsity: 98.3%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"../data/ratings.csv\")\n",
    "ratings.head()\n",
    "\n",
    "print(\"Total ratings:\", len(ratings))\n",
    "print(\"Unique users:\", ratings['userId'].nunique())\n",
    "print(\"Unique movies:\", ratings['movieId'].nunique())\n",
    "print(\"Average ratings per user:\", len(ratings) / ratings['userId'].nunique())\n",
    "print(\"Average ratings per movie:\", len(ratings) / ratings['movieId'].nunique())\n",
    "\n",
    "\n",
    "user_movie_matrix = ratings.pivot_table(\n",
    "    index='userId',\n",
    "    columns='movieId',\n",
    "    values='rating'\n",
    ")\n",
    "\n",
    "print(user_movie_matrix.shape)\n",
    "user_movie_matrix.head()\n",
    "\n",
    "missing = user_movie_matrix.isna().sum().sum()\n",
    "total = user_movie_matrix.size\n",
    "print(f\"Sparsity: {round((missing/total) * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8240b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>114885</td>\n",
       "      <td>31357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>113041</td>\n",
       "      <td>11862.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId   tmdbId\n",
       "0        1  114709    862.0\n",
       "1        2  113497   8844.0\n",
       "2        3  113228  15602.0\n",
       "3        4  114885  31357.0\n",
       "4        5  113041  11862.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = pd.read_csv(\"../data/links.csv\")\n",
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c0125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-2019 shape: (329, 10)\n",
      "2015-2025 shape: (790, 6)\n",
      "2023 IMDb shape: (209, 8)\n",
      "Columns 2011-2019:\n",
      " Index(['MovieName', 'Genre', 'Rating', 'Director', 'Actor', 'PeopleVote',\n",
      "       'Year', 'Hero_Rating', 'movie_rating', 'content_rating'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns 2015-2025:\n",
      " Index(['index', 'tittle', 'genre', 'overview', 'director', 'cast'], dtype='object')\n",
      "\n",
      "Columns IMDb 2023:\n",
      " Index(['Movie Name', 'Duration', 'IMdb rating', 'Rating', 'Description',\n",
      "       'Votes', 'Poster', 'Month of Release'],\n",
      "      dtype='object')\n",
      "Combined Tamil shape: (1328, 7)\n",
      "Old size: (4803, 3)\n",
      "New size: (6131, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moneshwar R\\AppData\\Local\\Temp\\ipykernel_22596\\3001067833.py:78: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  tamil_movies = pd.concat([t1, t3, t4], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>300204</td>\n",
       "      <td>Bottle Radha</td>\n",
       "      <td>when his wife sends him to rehab for his alcoh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>300205</td>\n",
       "      <td>Jigarthanda Double X</td>\n",
       "      <td>in 1975, a filmmaker agrees to collaborate on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>300206</td>\n",
       "      <td>Japan</td>\n",
       "      <td>a daring robbery in a jewellery showroom kicks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>300207</td>\n",
       "      <td>Raid</td>\n",
       "      <td>[208, raid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>300208</td>\n",
       "      <td>Chaitra</td>\n",
       "      <td>kathir's wife chaitra is a mentally affected h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                 title  \\\n",
       "6126  300204          Bottle Radha   \n",
       "6127  300205  Jigarthanda Double X   \n",
       "6128  300206                 Japan   \n",
       "6129  300207                  Raid   \n",
       "6130  300208               Chaitra   \n",
       "\n",
       "                                          movie_profile  \n",
       "6126  when his wife sends him to rehab for his alcoh...  \n",
       "6127  in 1975, a filmmaker agrees to collaborate on ...  \n",
       "6128  a daring robbery in a jewellery showroom kicks...  \n",
       "6129                                        [208, raid]  \n",
       "6130  kathir's wife chaitra is a mentally affected h...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tamil_2011_2019 = pd.read_csv(\"../data/tamil_movies_2011-2019.csv\")\n",
    "tamil_2015_2025 = pd.read_csv(\"../data/tamil_movies_2015-2025.csv\")\n",
    "tamil_imdb_2023 = pd.read_csv(\"../data/imdb_tamil_2023.csv\")\n",
    "\n",
    "print(\"2011-2019 shape:\", tamil_2011_2019.shape)\n",
    "print(\"2015-2025 shape:\", tamil_2015_2025.shape)\n",
    "print(\"2023 IMDb shape:\", tamil_imdb_2023.shape)\n",
    "\n",
    "print(\"Columns 2011-2019:\\n\", tamil_2011_2019.columns)\n",
    "print(\"\\nColumns 2015-2025:\\n\", tamil_2015_2025.columns)\n",
    "print(\"\\nColumns IMDb 2023:\\n\", tamil_imdb_2023.columns)\n",
    "\n",
    "t1 = tamil_2011_2019.copy()\n",
    "\n",
    "# Rename to our common schema\n",
    "t1 = t1.rename(columns={\n",
    "    'MovieName': 'title',\n",
    "    'Genre': 'genres',\n",
    "    'Director': 'director',\n",
    "    'Actor': 'cast',\n",
    "    'Rating': 'imdb_rating'      # use this as IMDb rating\n",
    "})\n",
    "\n",
    "# Create empty overview (this dataset doesn't have one)\n",
    "t1['overview'] = \"\"\n",
    "\n",
    "# Create unique dummy IDs (so they don’t clash with TMDB)\n",
    "t1['id'] = range(100000, 100000 + len(t1))\n",
    "\n",
    "# Keep only the columns we need\n",
    "t1 = t1[['id','title','overview','genres','cast','director','imdb_rating']]\n",
    "\n",
    "t1.head(2)\n",
    "\n",
    "\n",
    "t3 = tamil_2015_2025.copy()\n",
    "\n",
    "t3 = t3.rename(columns={\n",
    "    'tittle': 'title',     # note: your file spells it \"tittle\"\n",
    "    'genre': 'genres',\n",
    "    'director': 'director',\n",
    "    'cast': 'cast'\n",
    "})\n",
    "\n",
    "# But add imdb_rating as NaN (not available here)\n",
    "t3['imdb_rating'] = None\n",
    "\n",
    "# Create unique dummy IDs\n",
    "t3['id'] = range(200000, 200000 + len(t3))\n",
    "\n",
    "t3 = t3[['id','title','overview','genres','cast','director','imdb_rating']]\n",
    "\n",
    "t3.head(2)\n",
    "\n",
    "\n",
    "t4 = tamil_imdb_2023.copy()\n",
    "\n",
    "t4 = t4.rename(columns={\n",
    "    'Movie Name': 'title',\n",
    "    'IMdb rating': 'imdb_rating',\n",
    "    'Description': 'overview'\n",
    "})\n",
    "\n",
    "# We don’t have genres, cast, director here → create empty placeholders\n",
    "t4['genres'] = \"\"\n",
    "t4['cast'] = \"\"\n",
    "t4['director'] = \"\"\n",
    "\n",
    "# Create unique dummy IDs\n",
    "t4['id'] = range(300000, 300000 + len(t4))\n",
    "\n",
    "t4 = t4[['id','title','overview','genres','cast','director','imdb_rating']]\n",
    "\n",
    "t4.head(2)\n",
    "\n",
    "tamil_movies = pd.concat([t1, t3, t4], ignore_index=True)\n",
    "\n",
    "print(\"Combined Tamil shape:\", tamil_movies.shape)\n",
    "tamil_movies.head(3)\n",
    "\n",
    "\n",
    "def to_list(x):\n",
    "    if isinstance(x, str):\n",
    "        return [i.strip().lower().replace(\" \", \"\") for i in x.split(',')]\n",
    "    elif isinstance(x, list):\n",
    "        return [i.lower().replace(\" \", \"\") for i in x]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "tamil_movies['genres'] = tamil_movies['genres'].apply(to_list)\n",
    "tamil_movies['cast'] = tamil_movies['cast'].apply(to_list)\n",
    "tamil_movies['director'] = tamil_movies['director'].apply(lambda x: to_list(x))\n",
    "tamil_movies['overview'] = tamil_movies['overview'].fillna(\"\").apply(lambda x: x.lower().split())\n",
    "\n",
    "tamil_movies['movie_profile'] = (\n",
    "    tamil_movies['overview'] +\n",
    "    tamil_movies['genres'] +\n",
    "    tamil_movies['cast'] +\n",
    "    tamil_movies['director']\n",
    ")\n",
    "\n",
    "tamil_movies['movie_profile'] = tamil_movies['movie_profile'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "tamil_movies[['title','movie_profile']].head(2)\n",
    "\n",
    "tamil_final = tamil_movies[['id','title','movie_profile']]\n",
    "tamil_final.head()\n",
    "\n",
    "# Rename original_title → title in Hollywood data\n",
    "final_movies = final_movies.rename(columns={'original_title': 'title'})\n",
    "\n",
    "final_movies_extended = pd.concat([final_movies, tamil_final], ignore_index=True)\n",
    "\n",
    "print(\"Old size:\", final_movies.shape)\n",
    "print(\"New size:\", final_movies_extended.shape)\n",
    "\n",
    "final_movies_extended.to_csv(\"../data/final_movies_extended.csv\", index=False)\n",
    "\n",
    "final_movies_extended.head()\n",
    "final_movies_extended.tail()\n",
    "\n",
    "# If movie_profile is empty, use title words instead\n",
    "final_movies_extended['movie_profile'] = final_movies_extended.apply(\n",
    "    lambda row: row['title'].lower().replace(\".\", \"\").split()\n",
    "    if (isinstance(row['movie_profile'], str) and row['movie_profile'].strip() == \"\")\n",
    "    else row['movie_profile'],\n",
    "    axis=1\n",
    ")\n",
    "final_movies_extended['title'] = final_movies_extended['title'].str.replace(r'^\\d+\\.\\s*', '', regex=True)\n",
    "\n",
    "final_movies_extended.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffab1ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6131, 3)\n",
      "Index(['id', 'title', 'movie_profile'], dtype='object')\n",
      "New shape after removing duplicates: (5671, 3)\n",
      "New vector shape: (5671, 5000)\n",
      "Similarity matrix shape: (5671, 5671)\n",
      "Recommendations for Inception:\n",
      "\n",
      "['Duplex', 'The Helix... Loaded', 'Star Trek II: The Wrath of Khan', 'Timecop', 'Chicago Overcoat', 'Looper', 'Premium Rush', 'Transformers: Revenge of the Fallen', 'Congo', 'Flatliners']\n",
      "\n",
      "Recommendations for Jigarthanda Double X:\n",
      "\n",
      "['Mark Antony', 'Ok Kanmani', 'Kubera', 'Girl 6', 'Inside Deep Throat', 'Harrison Montgomery', 'Iraivi', 'Kadhai', 'Incident at Loch Ness', 'Baby and Baby']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_movies_extended = pd.read_csv(\"../data/final_movies_extended.csv\")\n",
    "\n",
    "print(final_movies_extended.shape)\n",
    "print(final_movies_extended.columns)\n",
    "\n",
    "# 1) Remove leading numbers like \"206. \"\n",
    "final_movies_extended['title'] = final_movies_extended['title'].str.replace(\n",
    "    r'^\\d+\\.\\s*', '', regex=True\n",
    ")\n",
    "\n",
    "# 2) Fix spacing issues (e.g., \"DoubleX\" -> \"Double X\")\n",
    "final_movies_extended['title'] = final_movies_extended['title'].str.replace(\n",
    "    r'DoubleX', 'Double X', regex=False\n",
    ")\n",
    "\n",
    "# 3) Remove extra spaces and standardize case\n",
    "final_movies_extended['title'] = (\n",
    "    final_movies_extended['title']\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Keep only the first occurrence of each title\n",
    "final_movies_extended = final_movies_extended.drop_duplicates(\n",
    "    subset=['title'], keep='first'\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"New shape after removing duplicates:\", final_movies_extended.shape)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "vectors = cv.fit_transform(final_movies_extended['movie_profile']).toarray()\n",
    "print(\"New vector shape:\", vectors.shape)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(vectors)\n",
    "print(\"Similarity matrix shape:\", similarity.shape)\n",
    "\n",
    "movie_index = pd.Series(\n",
    "    final_movies_extended.index,\n",
    "    index=final_movies_extended['title']\n",
    ").drop_duplicates()\n",
    "\n",
    "def recommend(movie):\n",
    "    idx = movie_index.get(movie)\n",
    "\n",
    "    if idx is None:\n",
    "        print(\"Movie not found in dataset\")\n",
    "        return []\n",
    "\n",
    "    sim_scores = list(enumerate(similarity[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    return final_movies_extended['title'].iloc[movie_indices].tolist()\n",
    "\n",
    "\n",
    "print(\"Recommendations for Inception:\\n\")\n",
    "print(recommend(\"Inception\"))\n",
    "\n",
    "print(\"\\nRecommendations for Jigarthanda Double X:\\n\")\n",
    "print(recommend(\"Jigarthanda Double X\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9257a25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   movieId  imdbId   tmdbId\n",
      "0        1  114709    862.0\n",
      "1        2  113497   8844.0\n",
      "2        3  113228  15602.0\n",
      "3        4  114885  31357.0\n",
      "4        5  113041  11862.0\n",
      "(610, 9724)\n",
      "(9724, 9724)\n",
      "Index(['movieId', 'title', 'genres'], dtype='object')\n",
      "['Dark Knight, The (2008)', 'Inglourious Basterds (2009)', 'Shutter Island (2010)', 'Dark Knight Rises, The (2012)', 'Fight Club (1999)', 'Interstellar (2014)', 'Up (2009)', 'Avengers, The (2012)', 'Django Unchained (2012)', 'Departed, The (2006)']\n",
      "['Toy Story 2 (1999)', 'Jurassic Park (1993)', 'Independence Day (a.k.a. ID4) (1996)', 'Star Wars: Episode IV - A New Hope (1977)', 'Forrest Gump (1994)', 'Lion King, The (1994)', 'Star Wars: Episode VI - Return of the Jedi (1983)', 'Mission: Impossible (1996)', 'Groundhog Day (1993)', 'Back to the Future (1985)']\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"../data/ratings.csv\")\n",
    "movies_ml = pd.read_csv(\"../data/movies.csv\")  \n",
    "links = pd.read_csv(\"../data/links.csv\")\n",
    "\n",
    "print(ratings.head())\n",
    "print(movies_ml.head())\n",
    "print(links.head())\n",
    "\n",
    "\n",
    "user_movie_matrix = ratings.pivot_table(\n",
    "    index='userId',\n",
    "    columns='movieId',\n",
    "    values='rating'\n",
    ")\n",
    "print(user_movie_matrix.shape)\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "movie_similarity_cf = cosine_similarity(\n",
    "    user_movie_matrix.T.fillna(0)\n",
    ")\n",
    "\n",
    "print(movie_similarity_cf.shape)\n",
    "\n",
    "print(movies_ml.columns)\n",
    "\n",
    "movie_id_map = movies_ml.set_index('movieId')['title']\n",
    "\n",
    "def recommend_cf(movie_title):\n",
    "    # find movieId\n",
    "    matches = movies_ml[movies_ml['title'].str.contains(movie_title, case=False)]\n",
    "    if matches.empty:\n",
    "        return []\n",
    "    \n",
    "    movie_id = matches.iloc[0]['movieId']\n",
    "    idx = list(user_movie_matrix.columns).index(movie_id)\n",
    "    \n",
    "    sim_scores = list(enumerate(movie_similarity_cf[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
    "    \n",
    "    movie_indices = [user_movie_matrix.columns[i[0]] for i in sim_scores]\n",
    "    return movie_id_map.loc[movie_indices].tolist()\n",
    "\n",
    "print(recommend_cf(\"Inception\"))\n",
    "print(recommend_cf(\"Toy Story\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a62132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID Inception:\n",
      "\n",
      "['Up', 'Shutter Island', 'The Avengers', 'Interstellar', 'The Dark Knight', 'The Dark Knight Rises', 'The Departed', 'Inglourious Basterds', 'Django Unchained', 'Fight Club']\n",
      "\n",
      "HYBRID Toy Story:\n",
      "\n",
      "['Toy Story', 'The Lion King', 'Forrest Gump', 'Back to the Future', 'Groundhog Day', 'Star Wars', 'Return of the Jedi', 'Mission: Impossible', 'Independence Day', 'Jurassic Park']\n",
      "\n",
      "HYBRID Jigarthanda Double X:\n",
      "\n",
      "['Mark Antony', 'Ok Kanmani', 'Kubera', 'Girl 6', 'Inside Deep Throat', 'Harrison Montgomery', 'Iraivi', 'Kadhai', 'Incident at Loch Ness', 'Baby and Baby']\n"
     ]
    }
   ],
   "source": [
    "links = pd.read_csv(\"../data/links.csv\")\n",
    "\n",
    "# Keep only valid mappings\n",
    "links = links.dropna(subset=['tmdbId'])\n",
    "\n",
    "links['tmdbId'] = links['tmdbId'].astype(int)\n",
    "\n",
    "ml_to_tmdb = links.set_index('movieId')['tmdbId'].to_dict()\n",
    "\n",
    "tmdb_to_content_index = pd.Series(\n",
    "    final_movies_extended.index,\n",
    "    index=final_movies_extended['id']\n",
    ").to_dict()\n",
    "\n",
    "def get_cf_scores(movie_title):\n",
    "    # CF recommendations (MovieLens titles)\n",
    "    cf_movies = recommend_cf(movie_title)\n",
    "    \n",
    "    scores = {}\n",
    "    \n",
    "    for title in cf_movies:\n",
    "        # find MovieLens id\n",
    "        match = movies_ml[movies_ml['title'] == title]\n",
    "        if match.empty:\n",
    "            continue\n",
    "        \n",
    "        ml_id = match.iloc[0]['movieId']\n",
    "        \n",
    "        # map to TMDB\n",
    "        if ml_id not in ml_to_tmdb:\n",
    "            continue\n",
    "        \n",
    "        tmdb_id = ml_to_tmdb[ml_id]\n",
    "        \n",
    "        # map to content index\n",
    "        if tmdb_id not in tmdb_to_content_index:\n",
    "            continue\n",
    "        \n",
    "        content_idx = tmdb_to_content_index[tmdb_id]\n",
    "        scores[content_idx] = 1  # simple uniform score\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def recommend_hybrid(movie, alpha=0.6):\n",
    "    # Content index\n",
    "    idx = movie_index.get(movie)\n",
    "    \n",
    "    if idx is None:\n",
    "        print(\"Movie not found in content dataset\")\n",
    "        return []\n",
    "    \n",
    "    # Content similarity scores\n",
    "    content_scores = list(enumerate(similarity[idx]))\n",
    "    \n",
    "    # Collaborative scores\n",
    "    cf_scores = get_cf_scores(movie)\n",
    "    \n",
    "    hybrid_scores = []\n",
    "    \n",
    "    for i, c_score in content_scores:\n",
    "        cf_score = cf_scores.get(i, 0)\n",
    "        \n",
    "        # Hybrid formula\n",
    "        final_score = alpha * c_score + (1 - alpha) * cf_score\n",
    "        hybrid_scores.append((i, final_score))\n",
    "    \n",
    "    hybrid_scores = sorted(hybrid_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
    "    movie_indices = [i[0] for i in hybrid_scores]\n",
    "    \n",
    "    return final_movies_extended['title'].iloc[movie_indices].tolist()\n",
    "\n",
    "\n",
    "print(\"HYBRID Inception:\\n\")\n",
    "print(recommend_hybrid(\"Inception\"))\n",
    "\n",
    "print(\"\\nHYBRID Toy Story:\\n\")\n",
    "print(recommend_hybrid(\"Toy Story\"))\n",
    "\n",
    "print(\"\\nHYBRID Jigarthanda Double X:\\n\")\n",
    "print(recommend_hybrid(\"Jigarthanda Double X\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "877f7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save similarity matrix\n",
    "with open(\"../data/similarity.pkl\", \"wb\") as f:\n",
    "    pickle.dump(similarity, f)\n",
    "\n",
    "# Save final dataset\n",
    "final_movies_extended.to_csv(\"../data/final_movies_extended.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collaborative_filtering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative Filtering Implementation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Fill NaN values with 0 for similarity calculation\n",
    "user_movie_filled = user_movie_matrix.fillna(0)\n",
    "\n",
    "# Calculate user-user similarity\n",
    "user_similarity = cosine_similarity(user_movie_filled)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, \n",
    "                                  index=user_movie_matrix.index, \n",
    "                                  columns=user_movie_matrix.index)\n",
    "\n",
    "def collaborative_recommend(user_id, n_recommendations=10):\n",
    "    if user_id not in user_movie_matrix.index:\n",
    "        return \"User not found\"\n",
    "    \n",
    "    # Get similar users\n",
    "    similar_users = user_similarity_df[user_id].sort_values(ascending=False)[1:11]\n",
    "    \n",
    "    # Get movies rated by similar users but not by target user\n",
    "    user_ratings = user_movie_matrix.loc[user_id]\n",
    "    unrated_movies = user_ratings[user_ratings.isna()].index\n",
    "    \n",
    "    recommendations = {}\n",
    "    \n",
    "    for movie in unrated_movies:\n",
    "        weighted_sum = 0\n",
    "        similarity_sum = 0\n",
    "        \n",
    "        for similar_user, similarity_score in similar_users.items():\n",
    "            if not pd.isna(user_movie_matrix.loc[similar_user, movie]):\n",
    "                weighted_sum += similarity_score * user_movie_matrix.loc[similar_user, movie]\n",
    "                similarity_sum += similarity_score\n",
    "        \n",
    "        if similarity_sum > 0:\n",
    "            recommendations[movie] = weighted_sum / similarity_sum\n",
    "    \n",
    "    # Sort and return top recommendations\n",
    "    sorted_recs = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [movie_id for movie_id, score in sorted_recs[:n_recommendations]]\n",
    "\n",
    "# Test collaborative filtering\n",
    "collab_recs = collaborative_recommend(1)\n",
    "print(f\"Collaborative recommendations for user 1: {collab_recs[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hybrid_system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Recommendation System\n",
    "links = pd.read_csv(\"../data/links.csv\")\n",
    "movies_meta = pd.read_csv(\"../data/movies.csv\")\n",
    "\n",
    "# Create mapping between MovieLens and TMDB IDs\n",
    "id_mapping = links.merge(movies_meta, on='movieId')[['movieId', 'tmdbId', 'title']]\n",
    "id_mapping = id_mapping.dropna(subset=['tmdbId'])\n",
    "id_mapping['tmdbId'] = id_mapping['tmdbId'].astype(int)\n",
    "\n",
    "def hybrid_recommend(user_id=None, movie_title=None, content_weight=0.5, collab_weight=0.5):\n",
    "    recommendations = set()\n",
    "    \n",
    "    # Content-based recommendations\n",
    "    if movie_title:\n",
    "        content_recs = recommend(movie_title)\n",
    "        if content_recs is not None:\n",
    "            recommendations.update(content_recs.tolist())\n",
    "    \n",
    "    # Collaborative filtering recommendations\n",
    "    if user_id:\n",
    "        collab_movie_ids = collaborative_recommend(user_id)\n",
    "        if collab_movie_ids != \"User not found\":\n",
    "            # Convert MovieLens IDs to movie titles\n",
    "            collab_titles = []\n",
    "            for movie_id in collab_movie_ids:\n",
    "                title_match = id_mapping[id_mapping['movieId'] == movie_id]\n",
    "                if not title_match.empty:\n",
    "                    tmdb_id = title_match.iloc[0]['tmdbId']\n",
    "                    tmdb_match = final_movies[final_movies['id'] == tmdb_id]\n",
    "                    if not tmdb_match.empty:\n",
    "                        collab_titles.append(tmdb_match.iloc[0]['original_title'])\n",
    "            recommendations.update(collab_titles)\n",
    "    \n",
    "    return list(recommendations)[:10]\n",
    "\n",
    "# Test hybrid system\n",
    "hybrid_recs = hybrid_recommend(user_id=1, movie_title=\"Inception\")\n",
    "print(f\"Hybrid recommendations: {hybrid_recs[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple evaluation metrics\n",
    "def calculate_coverage(recommendations, total_movies):\n",
    "    unique_recs = set()\n",
    "    for rec_list in recommendations:\n",
    "        unique_recs.update(rec_list)\n",
    "    return len(unique_recs) / total_movies\n",
    "\n",
    "def calculate_diversity(recommendations):\n",
    "    if not recommendations:\n",
    "        return 0\n",
    "    \n",
    "    total_pairs = 0\n",
    "    similar_pairs = 0\n",
    "    \n",
    "    for i in range(len(recommendations)):\n",
    "        for j in range(i+1, len(recommendations)):\n",
    "            total_pairs += 1\n",
    "            # Simple diversity check based on title similarity\n",
    "            if recommendations[i] != recommendations[j]:\n",
    "                similar_pairs += 1\n",
    "    \n",
    "    return similar_pairs / total_pairs if total_pairs > 0 else 0\n",
    "\n",
    "# Test evaluation\n",
    "sample_recs = [hybrid_recommend(user_id=i) for i in range(1, 6)]\n",
    "coverage = calculate_coverage(sample_recs, len(final_movies))\n",
    "print(f\"Coverage: {coverage:.3f}\")\n",
    "\n",
    "diversity = calculate_diversity(hybrid_recs)\n",
    "print(f\"Diversity: {diversity:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}